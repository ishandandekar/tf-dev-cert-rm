{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Convolutional Neural Networks and Computer Vision with Tensorflow\n",
        "\n",
        "\n",
        "Computer vision is the practice of writing algorithms which can discover patterns in visual data. Such as the camera of a self-driving car recognising a car infront.\n"
      ],
      "metadata": {
        "id": "M3WoiLzRkCG0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the data\n",
        "\n",
        "The images we're working with are from the Food101 dataset (101 different classes of food): https://www.kaggle.com/datasets/dansbecker/food-101  \n",
        "\n",
        "However we've modified it to only use two classes (pizza üçï & steak ü•©) using the image data modification notebook. https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/image_data_modification.ipynb\n",
        "\n",
        "> üîë**Note:** We start with a smaller dataset so we can experiment quickly and figure out what works (or better yet what doesn't work) before scaling up."
      ],
      "metadata": {
        "id": "Dsbr-nBYmNM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/pizza_steak.zip\n",
        "\n",
        "# Unzip the downloaded file\n",
        "zip_ref=zipfile.ZipFile(\"pizza_steak.zip\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "-930LIbXmMQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspect the data (become one with it)\n",
        "\n",
        "A very crucial step at the beginnning of any machine learning project is beconing one with the data.\n",
        "\n",
        "And for a computer vision project.. this usually means visualizing many samples of your data."
      ],
      "metadata": {
        "id": "sG5GKNORp2C2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls pizza_steak"
      ],
      "metadata": {
        "id": "nKjkG85xq3VI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls pizza_steak/train/"
      ],
      "metadata": {
        "id": "Y1JQVZCUq8bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls pizza_steak/train/steak"
      ],
      "metadata": {
        "id": "eaj955EprB9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Walk through pizza_steak directory and list number of files\n",
        "for dirpath,dirnames,filenames in os.walk(\"pizza_steak\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "id": "UDHZhGahrFmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Another way to find out how many images are in a file\n",
        "num_steak_images_train=len(os.listdir(\"pizza_steak/train/steak\"))\n",
        "\n",
        "num_steak_images_train"
      ],
      "metadata": {
        "id": "3ImKKu8Vrwu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualize our images, first let's get the class names programmatically."
      ],
      "metadata": {
        "id": "db9cL8f6srlL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the classnames programmatically\n",
        "import pathlib\n",
        "import numpy as np\n",
        "data_dir=pathlib.Path(\"pizza_steak/train\")\n",
        "class_names=np.array(sorted([item.name for item in data_dir.glob(\"*\")])) # Created a list of class names from the subdirectory\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "smxn4XDJsyd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's visualize our images\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "\n",
        "def view_random_image(target_dir,target_class):\n",
        "  # Setup the target directory (we'll view image from here)\n",
        "  target_folder=target_dir+target_class\n",
        "\n",
        "  # Get a random image path\n",
        "  random_image = random.sample(os.listdir(target_folder),1)\n",
        "\n",
        "  # Read in the imahe and plot it using matplotlib\n",
        "  img=mpimg.imread(target_folder+\"/\"+random_image[0])\n",
        "  plt.imshow(img)\n",
        "  plt.title(target_class)\n",
        "  plt.axis(\"off\");\n",
        "\n",
        "  print(f\"Image shape: {img.shape}\") # show the shape of the image\n",
        "  return img"
      ],
      "metadata": {
        "id": "f5lqb7b2tWEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View random image fro training dataset\n",
        "img=view_random_image(target_dir=\"pizza_steak/train/\",target_class=\"pizza\")"
      ],
      "metadata": {
        "id": "kuSXkz_Cv11l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The images we've imported and plotted are actually giant arrays/tensors of different pixel values\n",
        "import tensorflow as tf\n",
        "tf.constant(img)"
      ],
      "metadata": {
        "id": "FuR3_nI3AHPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View the image shape\n",
        "img.shape # returns width, height, color channels"
      ],
      "metadata": {
        "id": "4ZBPnmk4AfM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> üîë**Note:** As we've discussed before, many machine learning models, including neural networks prefer values they work with to be between 0 and 1. Knowing this, one of the most common preprocessing steps for working with images is to **scale** (also referred to as **normalize**) their pixel values by dividing the image arrays by 255 (since 255 is the maximum pixel value)."
      ],
      "metadata": {
        "id": "5EM7S5MQBLo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all the pixel values between 0 & 1\n",
        "img/255.0"
      ],
      "metadata": {
        "id": "5H1hlwEoA3a0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## An end-to-end example\n",
        "\n",
        "Let's build a convolutional neural network to find patterns in our images, more specifically we need a way to:\n",
        "* Load our images\n",
        "* Preprocess our images\n",
        "* Build a CNN to find patterns in our images\n",
        "* Compile our CNN\n",
        "* Fit the CNN to training data"
      ],
      "metadata": {
        "id": "CdARml10B5n3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Set the seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Preprocess data (get all of the pixel values between 0 & 1, also called scaling/normalization)\n",
        "train_datagen=ImageDataGenerator(rescale=1./255)\n",
        "valid_datagen=ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Setup path to our data directories\n",
        "train_dir=\"/content/pizza_steak/train\"\n",
        "test_dir=\"/content/pizza_steak/test\"\n",
        "\n",
        "# Import data from directories and turn it into batches\n",
        "train_data=train_datagen.flow_from_directory(directory=train_dir,\n",
        "                                              batch_size=32,\n",
        "                                              target_size=(224,224),\n",
        "                                              class_mode=\"binary\",\n",
        "                                              seed=42)\n",
        "valid_data=valid_datagen.flow_from_directory(directory=test_dir,\n",
        "                                             batch_size=32,\n",
        "                                             target_size=(224,224),\n",
        "                                             class_mode=\"binary\",\n",
        "                                             seed=42)\n",
        "\n",
        "# Build a CNN model (same as the Tiny VGG on the CNN explorer website)\n",
        "model_1=tf.keras.models.Sequential(\n",
        "    [\n",
        "     tf.keras.layers.Conv2D(filters=10,\n",
        "                            kernel_size=3,\n",
        "                            activation=\"relu\",\n",
        "                            input_shape=(224,224,3)),\n",
        "     tf.keras.layers.Conv2D(10,3,activation=\"relu\"),\n",
        "     tf.keras.layers.MaxPool2D(pool_size=2,\n",
        "                               padding=\"valid\"),\n",
        "     tf.keras.layers.Conv2D(10,3,activation=\"relu\"),\n",
        "     tf.keras.layers.Conv2D(10,3,activation=\"relu\"),\n",
        "     tf.keras.layers.MaxPool2D(2),\n",
        "     tf.keras.layers.Flatten(),\n",
        "     tf.keras.layers.Dense(1,activation=\"sigmoid\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Compile our CNN\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=\"Adam\",\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history_1=model_1.fit(train_data,\n",
        "                      epochs=5,\n",
        "                      steps_per_epoch=len(train_data),\n",
        "                      validation_data=valid_data,\n",
        "                      validation_steps=len(valid_data))"
      ],
      "metadata": {
        "id": "YVT7EhY1CaSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> üîë**Note:** If the above cell is taking longer than ~10 seconds per epoch, make sure you're using a GPU by going to Runtime -> Change Runtime Type -> Hardware Accelerator -> GPU.  \n",
        "You may have to rerun some cells above."
      ],
      "metadata": {
        "id": "8iq7zZ-MI-u7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a model summary\n",
        "model_1.summary()"
      ],
      "metadata": {
        "id": "O6bw4uhuJnnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚öí **Practice/exercise:** Go through the CNN explainer website for a minimum of 10-minutes and compare our neural network with theirs: https://poloclub.github.io/cnn-explainer/"
      ],
      "metadata": {
        "id": "PFRnlbUgKBwm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using the same model as before  \n",
        "Let's replicate the model we've made in the previous section to see if it works with our image data.  \n",
        "The model we're building is from the [Tensorflow playground](https://playground.tensorflow.org/#activation=relu&batchSize=30&dataset=circle&regDataset=reg-plane&learningRate=0.001&regularizationRate=1&noise=0&networkShape=4,4&seed=0.17454&showTestData=false&discretize=false&percTrainData=60&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)"
      ],
      "metadata": {
        "id": "gvJlDS3cSdjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model to replicate the Tensorflow playground model\n",
        "model_2=tf.keras.models.Sequential(\n",
        "    [\n",
        "     tf.keras.layers.Flatten(input_shape=(224,224,3)),\n",
        "     tf.keras.layers.Dense(4,activation=\"relu\"),\n",
        "     tf.keras.layers.Dense(4,activation=\"relu\"),\n",
        "     tf.keras.layers.Dense(1,activation=\"sigmoid\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=\"Adam\",\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history_2=model_2.fit(train_data,\n",
        "                      epochs=5,\n",
        "                      steps_per_epoch=len(train_data),\n",
        "                      validation_data=valid_data,\n",
        "                      validation_steps=len(valid_data))"
      ],
      "metadata": {
        "id": "lhINZM58SccG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a summary of model_2\n",
        "model_2.summary()"
      ],
      "metadata": {
        "id": "BGxOf5uxVHNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Despite having 20x more parameters than our CNN (model_1), model_2 performs terribly... let's try to improve it."
      ],
      "metadata": {
        "id": "Xn4xZmz_VS3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model (same as above but let's step it up a notch)\n",
        "model_3=tf.keras.models.Sequential(\n",
        "    [\n",
        "     tf.keras.layers.Flatten(input_shape=(224,224,3)),\n",
        "     tf.keras.layers.Dense(100,activation=\"relu\"),\n",
        "     tf.keras.layers.Dense(100,activation=\"relu\"),\n",
        "     tf.keras.layers.Dense(100,activation=\"relu\"),\n",
        "     tf.keras.layers.Dense(1,activation=\"sigmoid\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history_3=model_3.fit(train_data,\n",
        "                      epochs=5,\n",
        "                      steps_per_epoch=len(train_data),\n",
        "                      validation_data=valid_data,\n",
        "                      validation_steps=len(valid_data))"
      ],
      "metadata": {
        "id": "pK1So-LIVdi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the summary of model_3\n",
        "model_3.summary()"
      ],
      "metadata": {
        "id": "3XiNpD2bW4Xn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Note:** You can think of trainable parameters as **patterns a model can learn from data**. Intuitively, you might think more is better. And in lots of cases, it is. But in this case, the difference here is the two different styles of model we're using. Where a series of dense layers has a number of different learnable parameters connected to each other and hence a higher number of possible learnable patterns, **a convolutional neural network to sort out and learn the most important patterns in an image.** So even though theses are less learnable parameters in our convolutional neural network, theses are often more helpful in deciphering between different **features** in an image."
      ],
      "metadata": {
        "id": "_2rfcTSW8CZ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Binary Classification: Let's break it down\n",
        "\n",
        "1. Become one with the data (visualize, visualize, visualize)\n",
        "2. Preprocess the data (prepared it for our model, the main step here was scaling/normalizing)\n",
        "3. Created a model (start with a baseline)\n",
        "4. Fit the model\n",
        "5. Evaluate the model\n",
        "6. Adjust different params and improve our model\n",
        "7. Repeat until satisfied (experiment, experiment, experiment)"
      ],
      "metadata": {
        "id": "bxeBZWX0_1BG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Become one with the data"
      ],
      "metadata": {
        "id": "WaW0S2NRAaK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize data\n",
        "plt.figure()\n",
        "plt.subplot(1,2,1)\n",
        "steak_img=view_random_image(\"pizza_steak/train/\",\"steak\")\n",
        "plt.subplot(1,2,2)\n",
        "pizza_img=view_random_image(\"pizza_steak/train/\",\"pizza\")"
      ],
      "metadata": {
        "id": "ciMnW1Ni_0fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Preprocess the data (prepare it for a model)"
      ],
      "metadata": {
        "id": "jRxaOp45Bqtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define directory dataset paths\n",
        "train_dir=\"pizza_steak/train/\"\n",
        "test_dir=\"pizza_steak/test/\""
      ],
      "metadata": {
        "id": "BZxIx9zzBuN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our next step is to turn our data into **batches**.  \n",
        "A batch is a small subset of data. Rather than looking at all ~10000 images at one time, a model might only look at 32 at a time.  \n",
        "It does this for a couple of reasons:\n",
        "1. 10,000 images (or more)  might not fit into the memory of your processor (GPU).\n",
        "2. Trying to learn the patterns in 10,000 images in one hit could result in the model not being able to learn very well.  \n",
        "\n",
        "Why 32?  \n",
        "Because 32 is good for your health..."
      ],
      "metadata": {
        "id": "uB_90GRZB5yk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train and test data generators and rescale the data\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen=ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen=ImageDataGenerator(rescale=1/255.)"
      ],
      "metadata": {
        "id": "YEokckGtDbR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in our image data from directories and turn them into batches\n",
        "train_data=train_datagen.flow_from_directory(directory=train_dir,\n",
        "                                             target_size=(224,224),\n",
        "                                             class_mode=\"binary\",\n",
        "                                             batch_size=32)\n",
        "test_data=test_datagen.flow_from_directory(directory=test_dir,\n",
        "                                             target_size=(224,224),\n",
        "                                             class_mode=\"binary\",\n",
        "                                             batch_size=32)"
      ],
      "metadata": {
        "id": "iicc2AZMER4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a sample of a train data batch\n",
        "images,labels=train_data.next()\n",
        "len(images),len(labels)"
      ],
      "metadata": {
        "id": "al3jtMY6GaMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many batches are there\n",
        "len(train_data)"
      ],
      "metadata": {
        "id": "zk0FVJuOG4Ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the first two images\n",
        "images[:2],images[0].shape"
      ],
      "metadata": {
        "id": "HgmlHkvOG-v9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Create a CNN model (start with a baseline)\n",
        "A baseline is a relatively simple model or existing result that you setup when beginning a machine learning experiment and then as you keep experimenting, you try to beat the baseline.  \n",
        "\n",
        "> üîë**Note:** In deep learning, there is almost an infinite amount of architectures you could create. So one of the best ways to get started is to start with something simple and see if it works on your data and then introduce complexity as required (e.g. look at which current model is performing best in the field for your problem)."
      ],
      "metadata": {
        "id": "mralam5-Ifus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the creating of our model a little easier\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Activation\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "Q1KzTvBxK-Kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model (this will be our baseline, a layer convolutional neural network)\n",
        "model_4 = Sequential(\n",
        "    [\n",
        "     Conv2D(filters=10,\n",
        "            kernel_size=3,\n",
        "            padding=\"valid\",\n",
        "            activation=\"relu\",\n",
        "            input_shape=(224,224,3)), # input layer (specify input shape)\n",
        "     Conv2D(10,3,activation=\"relu\"),\n",
        "     Conv2D(10,3,activation=\"relu\"),\n",
        "     Flatten(),\n",
        "     Dense(1,activation=\"sigmoid\") # output layer (working with binary classification so only 1 output neuron)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "adh8bI2dIwWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚öí **Practice:** Understand what's going on in a Conv2D layer by going trhough the CNN explainer website for 10-20 minutes."
      ],
      "metadata": {
        "id": "WEcZuawHWLBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "tUhF9c9TZDdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Fit the model"
      ],
      "metadata": {
        "id": "9klw0jEQZQnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the summary of model\n",
        "model_4.summary()"
      ],
      "metadata": {
        "id": "ixnjjHYfZQRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the lengths of training and test data generators\n",
        "len(train_data),len(test_data)"
      ],
      "metadata": {
        "id": "lPwCXPgcZVYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "history_4 = model_4.fit(train_data,\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data=test_data,\n",
        "                        validation_steps=len(test_data))"
      ],
      "metadata": {
        "id": "08Q_5_eWZiAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Evaluating our model\n",
        "It looks like our model is learning something, let's evaluate it."
      ],
      "metadata": {
        "id": "q5Cnh8apagxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's plot the training curves\n",
        "import pandas as pd\n",
        "pd.DataFrame(history_4.history).plot(figsize=(10,7));"
      ],
      "metadata": {
        "id": "ruK_-tC_al_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the validation and training curves separately\n",
        "def plot_loss_curves(history):\n",
        "  \"\"\"\n",
        "  Returns separate loss curves for training and validation \n",
        "  \"\"\"\n",
        "  loss=history.history[\"loss\"]\n",
        "  val_loss=history.history[\"val_loss\"]\n",
        "\n",
        "  accuracy=history.history[\"accuracy\"]\n",
        "  val_accuracy=history.history[\"val_accuracy\"]\n",
        "\n",
        "  epochs=range(len(history.history[\"loss\"])) # how many epochs did we run for?\n",
        "\n",
        "  # Plot loss\n",
        "  plt.plot(epochs,loss,label=\"training loss\")\n",
        "  plt.plot(epochs,val_loss,label=\"val loss\")\n",
        "  plt.title(\"loss\")\n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.figure()\n",
        "  plt.plot(epochs,accuracy,label=\"training accuracy\")\n",
        "  plt.plot(epochs,val_accuracy,label=\"val accuracy\")\n",
        "  plt.title(\"accuracy\")\n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.legend();"
      ],
      "metadata": {
        "id": "rxvzLfsmbB1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> üîë**Note:** When a model's **validation loss starts to increase**, it's likely the model is **overfitting** the training dataset. This means, it's learning the patterns in the training dataset *too well* and thus the model's ability to generalize to unseen data will be diminished."
      ],
      "metadata": {
        "id": "WA701i3Ohb_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the loss and accuracy of model_4\n",
        "plot_loss_curves(history_4)"
      ],
      "metadata": {
        "id": "SrFEL-qkgfoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> üîë**Note:** Ideally the two loss curves (training and validation) will be similar to each other (training loss and validation loss decreasing at similar rates), when there are large differences your model may be **overfitting**."
      ],
      "metadata": {
        "id": "R7CKLVfkiKQE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Adjust the model parameters\n",
        "Fitting a machine learning model comes in 3 steps:\n",
        "0. Create a baseline model\n",
        "1. Beat the baseline by overfitting a larger model\n",
        "2. Reduce overfitting\n",
        "\n",
        "Ways to induce overfitting:\n",
        "* Increase the number of conv layers.\n",
        "* Increase the number of conv filters.\n",
        "* Add another dense layer to the output of our flattened layer.\n",
        "\n",
        "Reduce overfitting:\n",
        "* Add data augmentation.\n",
        "* Add regularization layers (such as MaxPool2D).\n",
        "* Add more data...\n",
        "\n",
        "> üîë**Note:** Reducing overfitting is also known as **regularization**."
      ],
      "metadata": {
        "id": "yXWXPFl9j7Ds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model (this is going to be our new baseline)\n",
        "model_5 = Sequential(\n",
        "    [\n",
        "     Conv2D(10,3,activation=\"relu\",input_shape=(224,224,3)),\n",
        "     MaxPool2D(pool_size=2),\n",
        "     Conv2D(10,3,activation=\"relu\"),\n",
        "     MaxPool2D(),\n",
        "     Conv2D(10,3,activation=\"relu\"),\n",
        "     MaxPool2D(),\n",
        "     Flatten(),\n",
        "     Dense(1,activation=\"sigmoid\")\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "kqte7NjpkjV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "H3fO-dfblPgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "history_5=model_5.fit(train_data,\n",
        "                      epochs=5,\n",
        "                      steps_per_epoch=len(train_data),\n",
        "                      validation_data=test_data,\n",
        "                      validation_steps=len(valid_data))"
      ],
      "metadata": {
        "id": "i53N3KicmhoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the summary of our model\n",
        "model_5.summary()"
      ],
      "metadata": {
        "id": "mL_QKMVHnE4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot loss curves\n",
        "plot_loss_curves(history_5)"
      ],
      "metadata": {
        "id": "rFm7MUPknRJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Opening our bag of tricks anf finding data augmentation"
      ],
      "metadata": {
        "id": "robv3xBBn818"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create ImageDataGenerator training instance with data augmentation\n",
        "train_datagen_augmented=ImageDataGenerator(rescale=1/255.,\n",
        "                                           rotation_range=0.2,\n",
        "                                           shear_range=0.2,\n",
        "                                           zoom_range=0.2,\n",
        "                                           height_shift_range=0.3,\n",
        "                                           horizontal_flip=True)\n",
        "\n",
        "# Create ImageDataGenerator without data augmentation\n",
        "train_datagen=ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "# Create ImageDataGenerator without data augmentation for test dataset\n",
        "test_datagen=ImageDataGenerator(rescale=1/255.)"
      ],
      "metadata": {
        "id": "M0a1tYSsoBit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ü§î**Question:** What is data augmentation?  \n",
        "\n",
        "Data augmentation is the process of altering our training data, leading it to have more diversity and in turn allowing our models to learn more generalizable (hopefully) patterns. Altering might mean adjusting the rotation of an image, flipping it, cropping it or something similar.\n",
        "\n",
        "Let's write some code to visualize data augmentation..."
      ],
      "metadata": {
        "id": "vmb6iEiNpOaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import data and augment it from training directory\n",
        "print(\"Augmented training data:\")\n",
        "train_data_augmented = train_datagen_augmented.flow_from_directory(train_dir,\n",
        "                                                                      target_size=(224,224),\n",
        "                                                                      class_mode=\"binary\",\n",
        "                                                                      shuffle=False) # For demonstration purpose only\n",
        "\n",
        "# Create non-augmented train data batches\n",
        "print(\"Non-augmented training data:\")\n",
        "train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                               target_size=(224,224),\n",
        "                                               batch_size=32,\n",
        "                                               class_mode=\"binary\",\n",
        "                                               shuffle=False)\n",
        "\n",
        "# Create non-augmented test data batches\n",
        "print(\"Non-augmented test data:\")\n",
        "train_data=train_datagen.flow_from_directory(test_dir,\n",
        "                                             target_size=(224,224),\n",
        "                                             batch_size=32,\n",
        "                                             class_mode=\"binary\")"
      ],
      "metadata": {
        "id": "Qz8ZWHzspNM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> üîë**Note:** Data augmentation is usually only performed on the training data. Using `ImageDataGenerator` built-in data augmentation parameters our images are left as they are in the directories but are modified as they're loaded into the model.  \n",
        "\n",
        "Finally... let's visualize some augmented data!!!"
      ],
      "metadata": {
        "id": "jhXa52b2tA-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get sample data batches\n",
        "images,labels=train_data.next()\n",
        "augmented_images,augmented_labels=train_data_augmented.next()"
      ],
      "metadata": {
        "id": "lABzkr5FAJWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show original image and augmented image\n",
        "import random\n",
        "random_number = random.randint(0,32) # our batch sizes are 32...\n",
        "print(f\"Showing image number {random_number}\")\n",
        "plt.imshow(images[random_number])\n",
        "plt.title(f\"Original image\")\n",
        "plt.axis(False)\n",
        "plt.figure()\n",
        "plt.imshow(augmented_images[random_number])\n",
        "plt.title(f\"Augmented image\")\n",
        "plt.axis(False);"
      ],
      "metadata": {
        "id": "gAFk7G5FAnyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've seen what augmented training data looks like, let's build a model and see how it learns on augmented data."
      ],
      "metadata": {
        "id": "vwDrWtTuC7vE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model (same as model_5)\n",
        "model_6=Sequential(\n",
        "    [\n",
        "     Conv2D(10,3,activation=\"relu\"),\n",
        "     MaxPool2D(pool_size=2),\n",
        "     Conv2D(10,3,activation=\"relu\"),\n",
        "     MaxPool2D(),\n",
        "     Conv2D(10,3,activation=\"relu\"),\n",
        "     MaxPool2D(),\n",
        "     Flatten(),\n",
        "     Dense(1,activation=\"sigmoid\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history_6 = model_6.fit(train_data_augmented, # fitting model_6 on augmented training data\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data_augmented),\n",
        "                        validation_data=test_data,\n",
        "                        validation_steps=len(test_data))"
      ],
      "metadata": {
        "id": "DMlXNf5hC6kH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check our models training curves\n",
        "plot_loss_curves(history_6)"
      ],
      "metadata": {
        "id": "42YG22k1FRuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's shuffle our augmented training data and train another model (the same as before) on it and see what happens."
      ],
      "metadata": {
        "id": "HoW3o2JWFpq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import data and augment it and shuffle from training directory\n",
        "train_data_augmented_shuffled=train_datagen_augmented.flow_from_directory(train_dir,\n",
        "                                                      target_size=(224,224),\n",
        "                                                      batch_size=32,\n",
        "                                                      class_mode=\"binary\",\n",
        "                                                      shuffle=True) # shuffle data this time"
      ],
      "metadata": {
        "id": "aW12XnwZFkyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model (same as model_5 and model_6)\n",
        "model_7=Sequential(\n",
        "    [\n",
        "     Conv2D(10,3,activation=\"relu\",input_shape=(224,224,3)),\n",
        "     MaxPool2D(),\n",
        "     Conv2D(10,3,activation=\"relu\"),\n",
        "     MaxPool2D(),\n",
        "     Conv2D(10,3,activation=\"relu\"),\n",
        "     MaxPool2D(),\n",
        "     Flatten(),\n",
        "     Dense(1,activation=\"sigmoid\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model_7.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history_7= model_7.fit(train_data_augmented_shuffled,\n",
        "                       epochs=5,\n",
        "                       steps_per_epoch=len(train_data_augmented_shuffled),\n",
        "                       validation_data=test_data,\n",
        "                       validation_steps=len(test_data))"
      ],
      "metadata": {
        "id": "OHzuidD7GWJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot loss curves\n",
        "plot_loss_curves(history_7)"
      ],
      "metadata": {
        "id": "wRsSKbLSH-w-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> üîë**Note:** When shuffling training data, the model gets exposed to all different kinds of data during training, thus enabling it to learn features across a wide array of images (in our case, pizza & steak at the same time instead of just pizza then steak)."
      ],
      "metadata": {
        "id": "pZUoBoCEShHQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Repeat until satisfied\n",
        "\n",
        "Since we've already beaten our baseline, there are a few things we could try to continue to improve our model:\n",
        "\n",
        "* Increase the number of model layers (e.g. add more `Conv2D`/`MaxPool2D` layers)\n",
        "* Increase the number of filters in each convolutional layer (e.g. from 10 to 32 or even 64)\n",
        "* Train for longer (more epochs)\n",
        "* Find an ideal learning rate\n",
        "* Get more data (given the model more opportunities to learn)\n",
        "* Use **transfer learning** to leverage what another image model has learn and adjust it for our own use case.\n",
        "\n",
        "> ‚öí **Practice:** Recreate the model on the CNN explainer website (same as `model_1`) and see how it performs on augmented shuffled data."
      ],
      "metadata": {
        "id": "s-uDtyEmTTVE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making a prediction with our trained model on our own custom data"
      ],
      "metadata": {
        "id": "WIoD75v9Vf_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Classes we're working with\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "XscZuW2vS3ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View our example image\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-steak.jpeg\n",
        "steak=mpimg.imread(\"03-steak.jpeg\")\n",
        "plt.imshow(steak)\n",
        "plt.axis(False);"
      ],
      "metadata": {
        "id": "Kl0ox04MVpz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the shape of our image\n",
        "steak.shape"
      ],
      "metadata": {
        "id": "-RhdjKgaWh0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> üîë**Note:** When you train a neural network and you want to make a prediction with it on your own custom data, it's important that your custom data (or new data) is preprocessed into the same format as the data your model was trained on."
      ],
      "metadata": {
        "id": "bILLJNI6W3O9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to import image and resize it to be able tobe used with our model\n",
        "def load_and_prep_image(filename,img_shape=224):\n",
        "  \"\"\"\n",
        "  Reads an image from filename, turns it into a tensor and \n",
        "  reshapes it into a (img_shape,img_shape,color_channels).\n",
        "  \"\"\"\n",
        "  # Read in the image\n",
        "  img=tf.io.read_file(filename)\n",
        "  # Decode the read file into a tensor\n",
        "  img=tf.image.decode_image(img)\n",
        "  # Resize the image\n",
        "  img=tf.image.resize(img,size=[img_shape,img_shape])\n",
        "  # Rescale the image (get all values between 0 and 1)\n",
        "  img=img/255.0\n",
        "  return img"
      ],
      "metadata": {
        "id": "zZ8dOR0aXK1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steak=load_and_prep_image('03-steak.jpeg')\n",
        "steak"
      ],
      "metadata": {
        "id": "if6_DNESZqc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred=model_7.predict(tf.expand_dims(steak,axis=0))"
      ],
      "metadata": {
        "id": "2ulkMjQwZ2mU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like our custom image is being put through our model, however, it curretly outputs a prediction probability, wouldn't it be nice if we could visualize the image as well as the model's prediction?"
      ],
      "metadata": {
        "id": "4xEsPBTxaXyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can index the predicted class by rounding the prediction probability and indexing it on the class names\n",
        "pred_class = class_names[int(tf.round(pred))]\n",
        "pred_class"
      ],
      "metadata": {
        "id": "2Blx7zAAaVxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_and_plot(model,filename,class_names=class_names):\n",
        "  \"\"\"\n",
        "  Imports an image located at filename, makes a prediction with model\n",
        "  and plots the image with the predicted class as the title.\n",
        "  \"\"\"\n",
        "\n",
        "  # Import the target image and preprocess it\n",
        "  img=load_and_prep_image(filename)\n",
        "\n",
        "  # Make a prediction\n",
        "  pred = model.predict(tf.expand_dims(img,axis=0))\n",
        "\n",
        "  # Get the predicted class\n",
        "  pred_class=class_names[int(tf.round(pred))]\n",
        "\n",
        "  # PLot the image and predicted class\n",
        "  plt.imshow(img)\n",
        "  plt.title(f\"Prediction: {pred_class}\")\n",
        "  plt.axis(False);"
      ],
      "metadata": {
        "id": "Hs6eminFbNHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test our model on a custom image\n",
        "pred_and_plot(model_7,\"03-steak.jpeg\")"
      ],
      "metadata": {
        "id": "6uNDlNoVchZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our model works! Let's try it on another image... this time pizza üçï"
      ],
      "metadata": {
        "id": "dWIt5gfOc6SU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download another test custom image\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-pizza-dad.jpeg\n",
        "pred_and_plot(model_7,'03-pizza-dad.jpeg')"
      ],
      "metadata": {
        "id": "tL9FnOcic3th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-class Image Classification\n",
        "\n",
        "We've just been through a bunch of the following steps with a binary classification problem(pizza vs. steak), now we're going to step things up a notch with 10 classes of food.\n",
        "\n",
        "1. Become one with the data\n",
        "2. Preproces the data (get it ready for a model)\n",
        "3. Create a model (start with a baseline)\n",
        "4. Fit the model (overfit to make sure it works)\n",
        "5. Evaluate the model\n",
        "6. Adjust different hyperparameters and improce the model (try to beat baseline/reduce overfitting)\n",
        "7. Repeat until satisfied"
      ],
      "metadata": {
        "id": "cyYBO9eZdehJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Import and become with the data"
      ],
      "metadata": {
        "id": "bYRINaVCOgR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip\n",
        "\n",
        "# Unzip our data\n",
        "zip_ref=zipfile.ZipFile(\"10_food_classes_all_data.zip\",\"r\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "RnZTi7u5Okcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Walk through 10 classes of food image data\n",
        "for dirpath, dirnames,filenames in os.walk(\"10_food_classes_all_data\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'\")"
      ],
      "metadata": {
        "id": "Vu7aQEEoPOPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the train and test directories\n",
        "train_dir=\"10_food_classes_all_data/train/\"\n",
        "test_dir=\"10_food_classes_all_data/test/\""
      ],
      "metadata": {
        "id": "kkhnWC6NQACn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's get the class names\n",
        "import pathlib\n",
        "import numpy as np\n",
        "data_dir=pathlib.Path(train_dir)\n",
        "class_names=np.array(sorted([item.name for item in data_dir.glob('*')]))\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "VBGho3a0SCNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize, visualize visualize\n",
        "import random\n",
        "img=view_random_image(target_dir=train_dir,\n",
        "                      target_class=random.choice(class_names))"
      ],
      "metadata": {
        "id": "ec4m6xYOR9DW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Preprocess the data (prepare it for a model)"
      ],
      "metadata": {
        "id": "jNzZdF1kTSUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Rescale\n",
        "train_datagen=ImageDataGenerator(rescale=1/255.0)\n",
        "test_datagen=ImageDataGenerator(rescale=1/255.0)\n",
        "\n",
        "# Load data in from directories and turn it into batches\n",
        "train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                               target_size=(224,224),\n",
        "                                               batch_size=32,\n",
        "                                               class_mode=\"categorical\")\n",
        "\n",
        "test_data=test_datagen.flow_from_directory(test_dir,\n",
        "                                           target_size=(224,224),\n",
        "                                           batch_size=32,\n",
        "                                           class_mode=\"categorical\")"
      ],
      "metadata": {
        "id": "74PohqEVTjz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Create a model (start with a baseline)\n",
        "\n",
        "We've been taling a lot about the CNN explainer website... how about we just take their model (also on 10 classes) and use it for our problem...?"
      ],
      "metadata": {
        "id": "5eNHoD5DV4Y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the functions and layers\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D,MaxPool2D,Flatten,Dense"
      ],
      "metadata": {
        "id": "IXRkBy6cWXIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model\n",
        "model_8=Sequential(\n",
        "    [\n",
        "     Conv2D(filters=10,kernel_size=(3,3),input_shape=(224,224,3),activation=\"relu\"),\n",
        "     Conv2D(10,3,activation=\"relu\"),\n",
        "     MaxPool2D(),\n",
        "     Conv2D(10,3,activation=\"relu\"),\n",
        "     Conv2D(10,3,activation=\"relu\"),\n",
        "     MaxPool2D(),\n",
        "     Flatten(),\n",
        "     Dense(10,activation=\"softmax\") # 10 units because 10 classes\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model_8.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=\"Adam\",\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "xIXP0At3V7Uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Fit the model"
      ],
      "metadata": {
        "id": "PFGE7CqJZkCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "history_8 = model_8.fit(train_data,\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data=test_data,\n",
        "                        validation_steps=len(test_data))"
      ],
      "metadata": {
        "id": "EKCkyuF5ZOW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Evaluate the model"
      ],
      "metadata": {
        "id": "jpepx7liA5Lr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the test data\n",
        "model_8.evaluate(test_data)"
      ],
      "metadata": {
        "id": "KSNszzm8A9Ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out loss curves\n",
        "plot_loss_curves(history_8)"
      ],
      "metadata": {
        "id": "4sOW8RC1COJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What do these loss curves tell us?\n",
        "\n",
        "Well... it seems our model is **overfitting** the training set quite badly... in other words, it's getting great results on the training data but fails to generalize well to unseen data and performs porrly on test dataset."
      ],
      "metadata": {
        "id": "iMFdDlZHCf4h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Adjust model hyperparameters (to beat the baseline/reduce overfitting) \n",
        "\n",
        "Due to its performance on the training data, it's clear our model is learning something...  \n",
        "However, it's not generalizing well to unseen data (overfitting).  \n",
        "So, let's try and fix overfitting by... \n",
        "* **Get more data** - having more data gives a model more opportunity to learn diverse patterns...\n",
        "* **Simplify the model** - if our current model is overfitting the data, it may be too complicated of a model, one way to simplify a model is to: reduce # of layers or reduce # of hidden units in layers.\n",
        "* **Use data augmentation** - data augmentation manipulates the training data in such a way to add more diversity to it (without altering the original data).\n",
        "* **Use transfer learning** - transfer learning leverages the patterns another model has learned on similar data to your own and allows you to use those patterns on your own dataset."
      ],
      "metadata": {
        "id": "W3ORPH6zC-vV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How about we try and simplify our model\n",
        "# Let's try to remove 2 convolutional layers\n",
        "\n",
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model\n",
        "model_9=Sequential(\n",
        "    [\n",
        "     Conv2D(10,3,activation=\"relu\",input_shape=(224,224,3)),\n",
        "     MaxPool2D(),\n",
        "     Conv2D(10,3,activation=\"relu\"),\n",
        "     MaxPool2D(),\n",
        "     Flatten(),\n",
        "     Dense(10,activation=\"softmax\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model_9.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=\"Adam\",\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history_9 = model_9.fit(train_data,\n",
        "                      epochs=5,\n",
        "                      steps_per_epoch=len(train_data),\n",
        "                      validation_data=test_data,\n",
        "                      validation_steps=len(test_data))"
      ],
      "metadata": {
        "id": "O2s1gDX1DEqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the loss curves\n",
        "plot_loss_curves(history_9)"
      ],
      "metadata": {
        "id": "iy6rAYovGi3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like our \"simplifying the model\" experiment didn't work... The accuracy went down and overfitting continued.  \n",
        "How about we try data augmentation?"
      ],
      "metadata": {
        "id": "E6x-yLQAGxNw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trying to reduce overfitting\n",
        "\n",
        "Let's try and improve our model's results by using augmented training data...  \n",
        "Ideally, we want to:\n",
        "* Reduce overfitting (get the train and validation loss curves closer)\n",
        "* Improve validation accuracy"
      ],
      "metadata": {
        "id": "Tj0iWjdKHDh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an augmented data generator instance\n",
        "train_datagen_augmented = ImageDataGenerator(rescale=1/255.0,\n",
        "                                             rotation_range=0.2,\n",
        "                                             width_shift_range=0.2,\n",
        "                                             height_shift_range=0.2,\n",
        "                                             zoom_range=0.2,\n",
        "                                             horizontal_flip=True)\n",
        "\n",
        "train_data_augmented=train_datagen_augmented.flow_from_directory(train_dir,\n",
        "                                                                 target_size=(224,224),\n",
        "                                                                 batch_size=32,\n",
        "                                                                 class_mode=\"categorical\")"
      ],
      "metadata": {
        "id": "0vaxokKEHBcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create another model but this time we'll fit it on the augmented training data of 10 classes\n",
        "model_10 = tf.keras.models.clone_model(model_8)\n",
        "\n",
        "# Compile the cloned model (using same setup as previous models)\n",
        "model_10.compile(loss=\"categorical_crossentropy\",\n",
        "                 optimizer=\"Adam\",\n",
        "                 metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "QsxloEN8IMnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_10.summary()"
      ],
      "metadata": {
        "id": "mMv6InW0nO_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "history_10 = model_10.fit(train_data_augmented,\n",
        "                          epochs=5,\n",
        "                          steps_per_epoch=len(train_data_augmented),\n",
        "                          validation_data=test_data,\n",
        "                          validation_steps=len(test_data))"
      ],
      "metadata": {
        "id": "uKWAS7hLpAiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_8.evaluate(test_data)"
      ],
      "metadata": {
        "id": "9_UTAV-KsQ4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_10.evaluate(test_data)"
      ],
      "metadata": {
        "id": "VKaN5_SWsTQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out our model trained on augmented data's loss curves\n",
        "plot_loss_curves(history_10)"
      ],
      "metadata": {
        "id": "kYVEawTvseUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Woah! that looks much better, the loss curves much closer to each other than the baseline model and they look like they're heading in the right direction (certainly not the wrong direction) so if we were to train for longer, we might see further improvement."
      ],
      "metadata": {
        "id": "wkR-A4BBu5-A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Repeat until satisfied\n",
        "\n",
        "We could keep going here... continuously trying to bring our loss curves closer together and trying to improve the validation/test accuracy. \n",
        "\n",
        "How?  \n",
        "\n",
        "By running lot's of experiments, namely:\n",
        "- restructuring our model's architecture (increasing layers/hidden units)\n",
        "- adjust the learning rate\n",
        "- try different methods of data augmentation (adjust the hyperparameters in our ImageDataGenerator instance)\n",
        "- training for longer (e.g. 10 epochs)\n",
        "- try **transfer learning**\n"
      ],
      "metadata": {
        "id": "P7DEz5NKvN_w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making a prediction with our trained model  \n",
        "\n",
        "Let's use our trained model to make some predictions on our own custom images!"
      ],
      "metadata": {
        "id": "EY3WmTnwwUXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remind ourselves of the classes our model is trained on\n",
        "class_names"
      ],
      "metadata": {
        "id": "CfppvOK_vMdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download some custom images\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-steak.jpeg\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-sushi.jpeg\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-pizza-dad.jpeg\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-hamburger.jpeg"
      ],
      "metadata": {
        "id": "7cI_pUhVw-ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reconfig pred_and_plot for multiple categories\n",
        "def pred_and_plot(model,filename,class_names=class_names):\n",
        "  \"\"\"\n",
        "  Imports an image located at filename, makes a prediction with model\n",
        "  and plots the image with the predicted class as the title.\n",
        "  \"\"\"\n",
        "\n",
        "  # Import the target image and preprocess it\n",
        "  img=load_and_prep_image(filename)\n",
        "\n",
        "  # Make a prediction\n",
        "  pred = model.predict(tf.expand_dims(img,axis=0))\n",
        "\n",
        "  # Add in logic for multi-class\n",
        "  if len(pred[0])>1:\n",
        "    pred_class=class_names[tf.argmax(pred[0])]\n",
        "  else:\n",
        "     pred_class=class_names[int(tf.round(pred[0]))]\n",
        "\n",
        "  # PLot the image and predicted class\n",
        "  plt.imshow(img)\n",
        "  plt.title(f\"Prediction: {pred_class}\")\n",
        "  plt.axis(False);"
      ],
      "metadata": {
        "id": "7mw43kseyCs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prediction using model_10\n",
        "pred_and_plot(model=model_10,\n",
        "              filename=\"03-pizza-dad.jpeg\",\n",
        "              class_names=class_names)"
      ],
      "metadata": {
        "id": "MsT4B28AxW-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prediction using model_10\n",
        "pred_and_plot(model=model_10,\n",
        "              filename=\"03-steak.jpeg\",\n",
        "              class_names=class_names)"
      ],
      "metadata": {
        "id": "SuL7_fZqysts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prediction using model_10\n",
        "pred_and_plot(model=model_10,\n",
        "              filename=\"03-sushi.jpeg\",\n",
        "              class_names=class_names)"
      ],
      "metadata": {
        "id": "EQaX9eYLyysk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prediction using model_10\n",
        "pred_and_plot(model=model_10,\n",
        "              filename=\"03-hamburger.jpeg\",\n",
        "              class_names=class_names)"
      ],
      "metadata": {
        "id": "1oU_nNkOy3wk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like our model didn't perform very well on our custom images but this because it only achieved ~39% accuracy on teh test data. So we can expect it to function quite poorly on other unseen data."
      ],
      "metadata": {
        "id": "sQGqAKlpzIV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving and loading our model"
      ],
      "metadata": {
        "id": "sB9b68q6zaaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save a model\n",
        "model_10.save(\"saved_trained_model_10\")"
      ],
      "metadata": {
        "id": "Ao7ieuAezYZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in a trained model and evaluate it\n",
        "loaded_model_10 = tf.keras.models.load_model(\"saved_trained_model_10\")\n",
        "loaded_model_10.evaluate(test_data)"
      ],
      "metadata": {
        "id": "bVZDbo2CzjMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare our loaded model to our existing model\n",
        "model_10.evaluate(test_data)"
      ],
      "metadata": {
        "id": "OU-pVbRMz1n6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}